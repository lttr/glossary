---
title: Tokens
date: 2025-06-25
tags:
  - ai
  - tokenization
  - language-processing
---

The smallest units of a language model, which can correspond to words, parts of words, or characters. For Claude, a token represents approximately 3.5 English characters.

Understanding tokens is crucial for managing costs, context limits, and optimizing prompts, as most AI services charge and limit usage based on token consumption.